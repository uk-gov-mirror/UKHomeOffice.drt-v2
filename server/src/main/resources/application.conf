# Config file in HOCON format.  See following for more information:
# https://www.playframework.com/documentation/latest/Configuration

application.cdn = ""
application.cdn = ${?APPLICATION_CDN}

play.http.parser.maxMemoryBuffer = 100m

portcode = "xxx"
portcode = ${?PORT_CODE}

env = ${?ENV}

contact-email = ${?CONTACT_EMAIL}

play.http.context = "/v2/"${portcode}"/live"

play.server.netty.maxHeaderSize = 32768
play.akka.actor-system = ${portcode}"-drt-actor-system"
play.akka.run-cs-from-phase = "before-cluster-shutdown"

persistenceBaseDir = "/tmp"
persistenceBaseDir = ${?PERSISTENCE_BASE_DIR}


feature-flags {
  nationality-based-processing-times = ${?NATIONALITY_BASED_PROC_TIMES}
  use-v2-staff-input: ${?USE_V2_STAFF_INPUT}
  lhr {
    use-new-lhr-feed: ${?USE_NEW_LHR_FEED}
  }
  use-splits-prediction: ${?USE_SPLITS_PREDICTION}
  super-user-mode: ${?SUPER_USER_MODE}
}

persistence {
  snapshot-interval {
    voyage-manifest: ${?SNAPSHOT_INTERVAL_VM}
  }
}

cluster = {
  0 {
    host = "127.0.0.1"
    host = ${?CLUSTER_SEED_NODE_HOST_1}
    port = 32810
    port = ${?CLUSTER_SEED_NODE_PORT_1}
  }
  1 {
    host = "127.0.0.1"
    host = ${?CLUSTER_SEED_NODE_HOST_2}
    port = 32811
    port = ${?CLUSTER_SEED_NODE_PORT_2}
  }
  2 {
    host = "127.0.0.1"
    host = ${?CLUSTER_SEED_NODE_HOST_3}
    port = 32812
    port = ${?CLUSTER_SEED_NODE_PORT_3}
  }
}

akka {
//  loglevel ="DEBUG"

  jvm-exit-on-fatal-error = true
  persistence {
    journal {
      plugin = "jdbc-journal"
    }
    snapshot-store {
      # Path to the snapshot store plugin to be used
      plugin = "jdbc-snapshot-store"
      // Enable the line below to automatically start the snapshot-store when the actorsystem is started
      auto-start-snapshot-stores = ["jdbc-snapshot-store"]
    }
  }

  cluster {
    min-nr-of-members = 1
    seed-nodes = [
      "akka.tcp://"${play.akka.actor-system}"@"${cluster.0.host}":"${cluster.0.port},
      "akka.tcp://"${play.akka.actor-system}"@"${cluster.1.host}":"${cluster.1.port},
      "akka.tcp://"${play.akka.actor-system}"@"${cluster.2.host}":"${cluster.2.port}
    ]
    singleton {
      singleton-name = "singleton"
      role = ""
      hand-over-retry-interval = 1s
      min-number-of-hand-over-retries = 10
    }
    singleton-proxy {
      singleton-name = ${akka.cluster.singleton.singleton-name}
      role = ""
      singleton-identification-interval = 10s
      buffer-size = 1000
    }
    # Sigar native library extract location during tests.
    # Note: use per-jvm-instance folder when running multiple jvm on one host.
    metrics.native-library-extract-folder=${user.dir}/target/native
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      hostname = ${?EXTERNAL_HOSTNAME}
      port = 32810
      port = ${?EXTERNAL_AKKA_PORT}

      bind-hostname = "127.0.0.1"
      bind-hostname = ${?INTERNAL_HOSTNAME}
      bind-port = 32810
      port = ${?INTERNAL_AKKA_PORT}
    }
    cluster {
      min-nr-of-members = 1
    }
  }

  actor {
    provider = "cluster"

    serializers {
      protobuf = "actors.serializers.ProtoBufSerializer"
    }
    serialization-bindings {
      "server.protobuf.messages.CrunchState.CrunchDiffMessage" = protobuf
      "server.protobuf.messages.FlightsMessage.FlightsDiffMessage" = protobuf
      "server.protobuf.messages.CrunchState.CrunchStateSnapshotMessage" = protobuf
      "server.protobuf.messages.ShiftMessage.ShiftStateSnapshotMessage" = protobuf
      "server.protobuf.messages.FixedPointMessage.FixedPointsStateSnapshotMessage" = protobuf
      "server.protobuf.messages.StaffMovementMessages.StaffMovementsStateSnapshotMessage" = protobuf
      "server.protobuf.messages.FlightsMessage.FlightStateSnapshotMessage" = protobuf
      "server.protobuf.messages.FlightsMessage.FeedStatusMessage" = protobuf
      "server.protobuf.messages.FlightsMessage.FeedStatusesMessage" = protobuf
      "server.protobuf.messages.VoyageManifest.VoyageManifestStateSnapshotMessage" = protobuf
      "server.protobuf.messages.VoyageManifest.VoyageManifestLatestFileNameMessage" = protobuf
      "server.protobuf.messages.VoyageManifest.VoyageManifestsMessage" = protobuf
      "server.protobuf.messages.VoyageManifest.VoyageManifestMessage" = protobuf
    }
  }
  stream.materializer {
    initial-input-buffer-size = 1
    max-input-buffer-size = 1
  }
}

jdbc-journal {
  slick = ${slick}
}
# the akka-persistence-snapshot-store in use
jdbc-snapshot-store {
  slick = ${slick}
}
# the akka-persistence-query provider in use
jdbc-read-journal {
  slick = ${slick}
}

slick {
  profile = "slick.jdbc.PostgresProfile$"
  db {
    host = "localhost"
    host = ${?POSTGRES_HOST}
    url = "jdbc:postgresql://"${slick.db.host}":5432/"${portcode}"?reWriteBatchedInserts=true"
    user = ""${portcode}""
    user = ${?POSTGRES_USER}
    password = ""${portcode}""
    password = ${?POSTGRES_PASSWORD}
    driver = "org.postgresql.Driver"
    numThreads = 5
    maxConnections = 5
    minConnections = 1
  }
}

passenger_splits_csv_url: ""
passenger_splits_csv_url: ${?PAX_SPLITS_CSV_URL}

walk_times {
  gates_csv_url = ""
  gates_csv_url = ${?GATES_WALK_TIMES_CSV_URL}
  stands_csv_url = ""
  stands_csv_url = ${?STANDS_WALK_TIMES_CSV_URL}
}

chroma {
  username = ""
  username = ${?CHROMA_USERNAME}
  password = ""
  password = ${?CHROMA_PASSWORD}
  url {
    token = ""
    token = ${?CHROMA_TOKEN_URL}
    live = ""
    live = ${?CHROMA_LIVE_URL}
    forecast = ""
    forecast = ${?CHROMA_FORECAST_URL}
  }
}

lhr {
  blackjack_url = ""
  blackjack_url = ${?BLACKJACK_URL}
  forecast_path = ${?LHR_FORECAST_PATH}
  live {
    url = ${?LHR_LIVE_URL}
    username = ${?LHR_LIVE_USERNAME}
    password = ${?LHR_LIVE_PASSWORD}
    api_url = ${?LHR_LIVE_API}
    token = ${?LHR_LIVE_TOKEN}
  }
  forecast {
    imap_server = ${?IMAP_SERVER}
    imap_port = ${?IMAP_PORT}
    imap_username = ${?IMAP_USERNAME}
    imap_password = ${?IMAP_PASSWORD}
    from_address = ${?LHR_FORECAST_FROM_EMAIL}
  }
}

acl {
  host = ""
  host = ${?ACL_HOST}
  username = ""
  username = ${?ACL_USERNAME}
  keypath = ""
  keypath = ${?ACL_KEYPATH}
}

dq {
  s3 {
    bucket = ${?DQ_S3_BUCKET}
    poll_frequency_seconds = ${?DQ_S3_POLL_FREQUENCY_SECONDS}
  }
  raw_zip_files_path = ${?DQ_RAW_ZIP_FILES_PATH}
}

crunch {
  recrunch-on-start = "false"
  recrunch-on-start = ${?RECRUNCH_ON_START}
  forecast {
    max_days = "360"
    max_days = ${?FORECAST_MAX_DAYS}
    poll_minutes = "120"
    poll_minutes = ${?FORECAST_POLL_MINUTES}
  }
  splits {
    raw-data-path = ${?RAW_SPLITS_DATA_PATH}
  }
}

feeds {
  gatwick {
    live {
      azure {
        namespace = ${?LGW_AZ_NAMESPACE}
        name.id = ${?LGW_AZ_NAME_ID}
        issuer = ${?LGW_AZ_ISSUER}
        cert = ${?LGW_CERT}
        private_cert = ${?LGW_PRIVATE_CERT}
      }
    }
    forecast {
      userId = ${?LGW_BOX_USER_ID}
      folderId = ${?LGW_BOX_FOLDER_ID}
      boxConfigFile = ${?LGW_BOX_CONFIG_FILE}
    }
  }
  bhx {
    soap {
      endPointUrl = ${?BHX_ENDPOINT_URL}
    }
  }
  ltn {
    live {
      url = ${?LTN_LIVE_URL}
      username = ${?LTN_LIVE_USERNAME}
      password = ${?LTN_LIVE_PASSWORD}
      token = ${?LTN_LIVE_TOKEN}
      timezone = ${?LTN_LIVE_TIMEZONE}
    }
  }
}
spray.can.client {
  request-timeout = 1 minutes
  idle-timeout    = 90 seconds
}
